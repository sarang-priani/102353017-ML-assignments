# -*- coding: utf-8 -*-
"""assignment(3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cXbaC3uuhFWi6xEAJamrbx_U2cisWhff
"""

# Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Square Error Fit)

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold, train_test_split

# Part (a) Load dataset and divide into input features and output variable
data = pd.read_csv("/content/USA_Housing.csv")
X = data.drop("Price", axis=1).values
y = data["Price"].values

# Part (b) Scale input features
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Part (c) Divide input and output features into five folds
kf = KFold(n_splits=5, shuffle=True, random_state=42)

best_r2 = -999
best_beta = None

# Part (d) Run five iterations and compute β, predicted values, and R2_score
for fold, (train_index, test_index) in enumerate(kf.split(X), 1):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    X_train_b = np.c_[np.ones(X_train.shape[0]), X_train]
    X_test_b = np.c_[np.ones(X_test.shape[0]), X_test]

    beta = np.linalg.inv(X_train_b.T @ X_train_b) @ X_train_b.T @ y_train
    y_pred = X_test_b @ beta
    r2 = r2_score(y_test, y_pred)
    print(f"Fold {fold}: R2 = {r2:.4f}")

    if r2 > best_r2:
        best_r2 = r2
        best_beta = beta

print("\nBest R2 from CV:", best_r2)

# Part (e) Use best β to train on 70% and test on 30% data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_train_b = np.c_[np.ones(X_train.shape[0]), X_train]
X_test_b = np.c_[np.ones(X_test.shape[0]), X_test]

y_pred = X_test_b @ best_beta
final_r2 = r2_score(y_test, y_pred)

print("\nFinal R2 on 30% test data:", final_r2)

#question 2
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

data = pd.read_csv("/content/USA_Housing.csv")
X = data.drop("Price", axis=1).values
y = data["Price"].values

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42)

X_train_b = np.c_[np.ones(X_train.shape[0]), X_train]
X_val_b = np.c_[np.ones(X_val.shape[0]), X_val]
X_test_b = np.c_[np.ones(X_test.shape[0]), X_test]

learning_rates = [0.001, 0.01, 0.1, 1]
num_iterations = 1000

best_r2_val = -np.inf
best_beta = None

for lr in learning_rates:
    beta = np.zeros(X_train_b.shape[1])
    for i in range(num_iterations):
        y_pred_train = X_train_b @ beta
        error = y_pred_train - y_train
        beta = beta - lr * (X_train_b.T @ error) / X_train_b.shape[0]
    y_val_pred = X_val_b @ beta
    y_test_pred = X_test_b @ beta
    r2_val = r2_score(y_val, y_val_pred)
    r2_test = r2_score(y_test, y_test_pred)
    print(f"Learning rate={lr}: R2_val={r2_val:.4f}, R2_test={r2_test:.4f}")
    if r2_val > best_r2_val:
        best_r2_val = r2_val
        best_beta = beta

print(best_beta)

#q3
# 1: Load dataset and handle missing values
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import PCA
from sklearn.metrics import r2_score

column_names = ["symboling", "normalized_losses", "make", "fuel_type", "aspiration",
                "num_doors", "body_style", "drive_wheels", "engine_location", "wheel_base",
                "length", "width", "height", "curb_weight", "engine_type", "num_cylinders",
                "engine_size", "fuel_system", "bore", "stroke", "compression_ratio",
                "horsepower", "peak_rpm", "city_mpg", "highway_mpg", "price"]

data = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data",
                   names=column_names, na_values='?')

for col in data.columns:
    if data[col].dtype == object:
        data[col].fillna(data[col].mode()[0], inplace=True)
    else:
        data[col].fillna(data[col].mean(), inplace=True)

data.dropna(subset=['price'], inplace=True)

# 2: Convert categorical columns to numeric
num_map = {'two':2,'four':4,'six':6,'five':5,'eight':8,'three':3,'twelve':12}
data['num_doors'] = data['num_doors'].map(num_map)
data['num_cylinders'] = data['num_cylinders'].map(num_map)

data = pd.get_dummies(data, columns=['body_style','drive_wheels'], drop_first=True)

label_cols = ['make','aspiration','engine_location','fuel_type']
le = LabelEncoder()
for col in label_cols:
    data[col] = le.fit_transform(data[col])

data['fuel_system'] = data['fuel_system'].apply(lambda x: 1 if 'pfi' in x else 0)
data['engine_type'] = data['engine_type'].apply(lambda x: 1 if 'ohc' in x else 0)

# 3: Split features and target, scale input
X = data.drop('price', axis=1)
y = data['price']
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4: Train linear regression on original data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)
r2_original = r2_score(y_test, y_pred)
print("R2 score on original data:", r2_original)

# 5: PCA + linear regression
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)
X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)
lr_pca = LinearRegression()
lr_pca.fit(X_train_pca, y_train_pca)
y_pred_pca = lr_pca.predict(X_test_pca)
r2_pca = r2_score(y_test_pca, y_pred_pca)
print("R2 score after PCA:", r2_pca)